# Quick Usage Guide

## ğŸš€ Running the RAG System

### Interactive Demo (Recommended)
```bash
python apps/rag_demo.py
```

### Command Line Interface
```bash
# Show system status
python apps/main.py --status

# Index documents from a directory
python apps/main.py --index ./documents

# Ask a question
python apps/main.py --query "What is artificial intelligence?"

# Ask with custom settings
python apps/main.py --query "How does ML work?" --top-k 3
```

## ğŸ“¦ Project Structure

```
RAG-Python-Code/
â”œâ”€â”€ ğŸš€ apps/                       # Application entry points
â”‚   â”œâ”€â”€ main.py                    # CLI application
â”‚   â””â”€â”€ rag_demo.py               # Interactive demo
â”‚
â”œâ”€â”€ ğŸ“¦ indexing/                   # Document processing
â”œâ”€â”€ ğŸ” searching/                  # Query & response generation  
â”œâ”€â”€ âš™ï¸ config/                     # Configuration management
â”œâ”€â”€ ğŸ› ï¸ utils/                      # Shared utilities
â”œâ”€â”€ ğŸ“„ docs/                      # Documentation
â”‚
â”œâ”€â”€ ğŸ“ documents/                  # Place PDF files here
â”œâ”€â”€ ğŸ—ƒï¸ vector_db/                  # Database storage
â””â”€â”€ ğŸ“‹ requirements.txt            # Dependencies
```

## ğŸ¯ Key Features

- **Document Indexing**: PDF processing with intelligent chunking
- **Smart Search**: Vector similarity search with semantic understanding
- **AI Responses**: Context-aware answer generation using LLMs
- **Multiple Interfaces**: Both CLI and interactive demo modes
- **Modular Design**: Clean package separation for easy maintenance

## ğŸ”§ Quick Setup

1. Install dependencies: `pip install -r requirements.txt`
2. Start Ollama: `ollama serve`
3. Install model: `ollama pull deepseek-r1:latest`
4. Add PDFs to `./documents/` folder
5. Run demo: `python apps/rag_demo.py`

---
**Ready to explore your documents with AI! ğŸ¤–ğŸ“š**